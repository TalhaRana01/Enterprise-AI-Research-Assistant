# AI Research Assistant ğŸ”

An enterprise-grade AI-powered research assistant that helps researchers, students, and professionals find, analyze, and summarize academic papers and research materials.

## ğŸ—ï¸ Project Structure

```
ai-research-assistant/
â”œâ”€â”€ backend/                    # FastAPI Backend
â”‚   â”œâ”€â”€ src/                    # Source code
â”‚   â”‚   â”œâ”€â”€ main.py            # FastAPI app entry point
â”‚   â”‚   â”œâ”€â”€ agents/            # AI agents
â”‚   â”‚   â”œâ”€â”€ chains/            # LangChain chains
â”‚   â”‚   â”œâ”€â”€ tools/             # Agent tools
â”‚   â”‚   â”œâ”€â”€ loaders/           # Document loaders
â”‚   â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”‚   â”œâ”€â”€ config/            # Configuration
â”‚   â”‚   â”œâ”€â”€ prompts/           # Prompt templates
â”‚   â”‚   â””â”€â”€ utils/             # Utilities
â”‚   â”œâ”€â”€ tests/                 # Test suite
â”‚   â”œâ”€â”€ scripts/               # Utility scripts
â”‚   â”œâ”€â”€ data/                  # Local data storage
â”‚   â”œâ”€â”€ logs/                  # Application logs
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â””â”€â”€ pytest.ini             # Pytest configuration
â”‚
â”œâ”€â”€ frontend/                   # Frontend (React.js/Streamlit)
â”‚   â””â”€â”€ README.md              # Frontend setup guide
â”‚
â”œâ”€â”€ docker-compose.yml          # Full stack deployment
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ .cursorrules                # Cursor AI rules
â””â”€â”€ README.md                   # This file
```

## âœ¨ Features

- ğŸ” **Multi-Source Search**: Search across ArXiv, PubMed, Google Scholar, and more
- ğŸ“„ **Smart Summarization**: AI-powered paper summaries with key insights
- ğŸ“š **Citation Management**: Automatic citation generation in multiple formats
- ğŸ’¬ **Interactive Q&A**: Ask questions about papers and get contextual answers
- ğŸ¯ **Semantic Search**: Find relevant papers based on meaning, not just keywords
- ğŸ“Š **Research Insights**: Extract key findings, methodologies, and conclusions
- ğŸ”— **Reference Tracking**: Track citations and related papers
- ğŸ“¥ **Export Options**: Export summaries, notes, and citations

## ğŸ› ï¸ Tech Stack

### Backend
- **Framework**: FastAPI 0.109+
- **AI Framework**: LangChain 0.1.0+
- **LLM**: OpenAI GPT-4 / GPT-3.5-turbo
- **Vector DB**: Pinecone (production) / Chroma (development)
- **Embeddings**: OpenAI text-embedding-3-small
- **Database**: PostgreSQL 14+
- **Cache**: Redis 7.0+
- **Monitoring**: LangSmith + Prometheus + Grafana

### Frontend
- **Framework**: React.js (recommended) or Streamlit
- **Status**: ğŸš§ In Development

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Node.js 18+ (for React.js frontend)
- Docker & Docker Compose (optional)

### Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Setup environment variables
cp .env.example .env
# Edit .env with your API keys

# Run the backend server
uvicorn src.main:app --reload --port 8000
```

### Frontend Setup

**React.js (Recommended):**
```bash
cd frontend
npm install
npm run dev
```

**Streamlit:**
```bash
cd frontend
pip install -r requirements.txt
streamlit run main.py
```

### Docker Setup (Full Stack)

```bash
# Start all services
docker-compose up --build

# Backend API: http://localhost:8000
# Frontend: http://localhost:3000
# API Docs: http://localhost:8000/docs
```

## ğŸ“¡ API Endpoints

### Search Papers
```bash
GET /api/v1/search?query=transformer+models&max_results=10
POST /api/v1/search
{
  "query": "transformer models in NLP",
  "max_results": 10
}
```

### Chat/Q&A
```bash
POST /api/v1/chat
{
  "question": "What are the key findings?",
  "paper_ids": ["arxiv:2301.12345"]
}

POST /api/v1/chat/stream  # Streaming response
```

### Papers Management
```bash
POST /api/v1/papers/summarize
GET /api/v1/papers/{paper_id}/summarize
POST /api/v1/papers/cite
GET /api/v1/papers/{paper_id}
```

### Health Check
```bash
GET /health
```

## ğŸ“ Directory Structure Details

### Backend (`backend/`)
- **`src/agents/`**: AI agents (Search, Q&A, Summarization, Router)
- **`src/chains/`**: LangChain chains (RAG, Citation, Summarization)
- **`src/tools/`**: Agent tools (ArXiv, PDF, Search)
- **`src/loaders/`**: Document loaders (ArXiv, PDF)
- **`src/api/`**: FastAPI routes and schemas
- **`src/config/`**: Configuration management
- **`src/prompts/`**: Prompt templates
- **`tests/`**: Unit, integration, and E2E tests

### Frontend (`frontend/`)
- **Status**: ğŸš§ Ready for React.js or Streamlit setup
- See `FRONTEND_COMPARISON.md` for options

## ğŸ”§ Configuration

### Backend Environment Variables

Create `backend/.env`:

```env
# Environment
ENVIRONMENT=development
DEBUG=true

# API Configuration
API_V1_PREFIX=/api/v1
SECRET_KEY=your-secret-key-here

# OpenAI
OPENAI_API_KEY=your-openai-key-here
LLM_MODEL=gpt-4
EMBEDDING_MODEL=text-embedding-3-small

# Vector Database
VECTOR_DB_TYPE=chroma  # or pinecone
CHROMA_PERSIST_DIRECTORY=./data/chroma

# Pinecone (if using)
PINECONE_API_KEY=your-pinecone-key
PINECONE_INDEX_NAME=research-papers

# Database
DATABASE_URL=postgresql://user:pass@localhost:5432/research_db

# Redis
REDIS_URL=redis://localhost:6379/0

# Monitoring
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=ai-research-assistant
LANGCHAIN_API_KEY=your-langsmith-key
```

## ğŸ§ª Testing

```bash
cd backend

# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/unit/test_agents.py -v
```

## ğŸ“š Documentation

- **Backend API Docs**: http://localhost:8000/docs (Swagger UI)
- **Testing Guide**: `backend/TESTING_GUIDE.md`
- **Frontend Comparison**: `FRONTEND_COMPARISON.md`
- **Quick Start**: `QUICK_START.md`

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend       â”‚
â”‚   (React.js)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/REST
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚  Backend â”‚
    â”‚ (FastAPI)â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚  Router    â”‚      â”‚  Q&A Agent   â”‚
â”‚  Agent     â”‚      â”‚  (RAG)       â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚                        â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚ ArXiv API  â”‚      â”‚  Vector DB   â”‚
â”‚ PubMed API â”‚      â”‚  (Pinecone)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš§ Roadmap

### Phase 1 (Completed) âœ…
- [x] Backend API with FastAPI
- [x] LangChain agents and chains
- [x] ArXiv integration
- [x] RAG system
- [x] Basic testing

### Phase 2 (In Progress) ğŸš§
- [ ] Frontend (React.js)
- [ ] User authentication
- [ ] Advanced search filters
- [ ] Citation management UI

### Phase 3 (Planned) ğŸ“‹
- [ ] Multi-source search (PubMed, Scholar)
- [ ] User profiles and saved papers
- [ ] Collaborative features
- [ ] Mobile app (React Native)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- LangChain for the AI framework
- OpenAI for LLM capabilities
- FastAPI for the web framework
- ArXiv for research paper access

---

**Built with â¤ï¸ for the research community**
